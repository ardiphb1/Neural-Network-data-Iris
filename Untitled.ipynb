{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mempersiapkan package yang akan digunakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset dari folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  \\\n",
      "0      1            5.1           3.5            1.4           0.2   \n",
      "1      2            4.9           3.0            1.4           0.2   \n",
      "2      3            4.7           3.2            1.3           0.2   \n",
      "3      4            4.6           3.1            1.5           0.2   \n",
      "4      5            5.0           3.6            1.4           0.2   \n",
      "..   ...            ...           ...            ...           ...   \n",
      "145  146            6.7           3.0            5.2           2.3   \n",
      "146  147            6.3           2.5            5.0           1.9   \n",
      "147  148            6.5           3.0            5.2           2.0   \n",
      "148  149            6.2           3.4            5.4           2.3   \n",
      "149  150            5.9           3.0            5.1           1.8   \n",
      "\n",
      "            Species  \n",
      "0       Iris-setosa  \n",
      "1       Iris-setosa  \n",
      "2       Iris-setosa  \n",
      "3       Iris-setosa  \n",
      "4       Iris-setosa  \n",
      "..              ...  \n",
      "145  Iris-virginica  \n",
      "146  Iris-virginica  \n",
      "147  Iris-virginica  \n",
      "148  Iris-virginica  \n",
      "149  Iris-virginica  \n",
      "\n",
      "[150 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "data_iris = pd.read_csv('Iris_Dataset.csv')\n",
    "print(data_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalisasi dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Normalisasi dataset untuk masing-masing column dengan pendekatan skala min - max, sehingga mempunyai fixed range [0,1]\n",
    "Xnorm = (X - Xmin) / (Xmax - Xmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaling(df):\n",
    "    # copy the dataframe\n",
    "    df_norm = df.copy()\n",
    "    # apply min-max scaling\n",
    "    for column in df_norm.columns:\n",
    "        df_norm[column] = (df_norm[column] - df_norm[column].min()) / (df_norm[column].max() - df_norm[column].min())\n",
    "    return df_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalisai dataset untuk masing-masing column dengan pendekatan skala min - max, sehingga mempunyai fixed range [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
      "0         0.222222      0.625000       0.067797      0.041667\n",
      "1         0.166667      0.416667       0.067797      0.041667\n",
      "2         0.111111      0.500000       0.050847      0.041667\n",
      "3         0.083333      0.458333       0.084746      0.041667\n",
      "4         0.194444      0.666667       0.067797      0.041667\n",
      "..             ...           ...            ...           ...\n",
      "145       0.666667      0.416667       0.711864      0.916667\n",
      "146       0.555556      0.208333       0.677966      0.750000\n",
      "147       0.611111      0.416667       0.711864      0.791667\n",
      "148       0.527778      0.583333       0.745763      0.916667\n",
      "149       0.444444      0.416667       0.694915      0.708333\n",
      "\n",
      "[150 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "norm_data_iris = min_max_scaling(data_iris[['SepalLengthCm', 'SepalWidthCm','PetalLengthCm','PetalWidthCm']])\n",
    "print(norm_data_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Konversi Species label setiap kelas menjadi index 0, 1 dan 2\n",
    "##### Iris-setosa = 0\n",
    "##### Iris-versicolor = 1\n",
    "##### Iris-virginica = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Species\n",
      "0          0\n",
      "1          0\n",
      "2          0\n",
      "3          0\n",
      "4          0\n",
      "..       ...\n",
      "145        2\n",
      "146        2\n",
      "147        2\n",
      "148        2\n",
      "149        2\n",
      "\n",
      "[150 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "target_output = data_iris[['Species']].replace(['Iris-setosa','Iris-versicolor','Iris-virginica'],[0,1,2])\n",
    "print(target_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menggabungkan label ke tabel normalization iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Species\n",
      "0         0.222222      0.625000       0.067797      0.041667        0\n",
      "1         0.166667      0.416667       0.067797      0.041667        0\n",
      "2         0.111111      0.500000       0.050847      0.041667        0\n",
      "3         0.083333      0.458333       0.084746      0.041667        0\n",
      "4         0.194444      0.666667       0.067797      0.041667        0\n",
      "..             ...           ...            ...           ...      ...\n",
      "145       0.666667      0.416667       0.711864      0.916667        2\n",
      "146       0.555556      0.208333       0.677966      0.750000        2\n",
      "147       0.611111      0.416667       0.711864      0.791667        2\n",
      "148       0.527778      0.583333       0.745763      0.916667        2\n",
      "149       0.444444      0.416667       0.694915      0.708333        2\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "norm_data_iris = pd.concat([norm_data_iris, target_output], axis=1)\n",
    "print(norm_data_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define persentase data untuk \\\"test\\\", dan buat satu column \\\"training\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True = data trainig & False = data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Species  \\\n",
      "0         0.222222      0.625000       0.067797      0.041667        0   \n",
      "1         0.166667      0.416667       0.067797      0.041667        0   \n",
      "2         0.111111      0.500000       0.050847      0.041667        0   \n",
      "3         0.083333      0.458333       0.084746      0.041667        0   \n",
      "4         0.194444      0.666667       0.067797      0.041667        0   \n",
      "..             ...           ...            ...           ...      ...   \n",
      "145       0.666667      0.416667       0.711864      0.916667        2   \n",
      "146       0.555556      0.208333       0.677966      0.750000        2   \n",
      "147       0.611111      0.416667       0.711864      0.791667        2   \n",
      "148       0.527778      0.583333       0.745763      0.916667        2   \n",
      "149       0.444444      0.416667       0.694915      0.708333        2   \n",
      "\n",
      "     training  \n",
      "0        True  \n",
      "1        True  \n",
      "2       False  \n",
      "3        True  \n",
      "4        True  \n",
      "..        ...  \n",
      "145      True  \n",
      "146      True  \n",
      "147      True  \n",
      "148     False  \n",
      "149      True  \n",
      "\n",
      "[150 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "persentase_test_training = 90/100.0\n",
    "norm_data_iris['training'] = np.random.rand(len(norm_data_iris)) < persentase_test_training\n",
    "print(norm_data_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buat dataset untuk training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Species\n",
      "129       0.805556      0.416667       0.813559      0.625000        2\n",
      "38        0.027778      0.416667       0.050847      0.041667        0\n",
      "102       0.777778      0.416667       0.830508      0.833333        2\n",
      "19        0.222222      0.750000       0.084746      0.083333        0\n",
      "87        0.555556      0.125000       0.576271      0.500000        1\n",
      "..             ...           ...            ...           ...      ...\n",
      "64        0.361111      0.375000       0.440678      0.500000        1\n",
      "20        0.305556      0.583333       0.118644      0.041667        0\n",
      "77        0.666667      0.416667       0.677966      0.666667        1\n",
      "119       0.472222      0.083333       0.677966      0.583333        2\n",
      "109       0.805556      0.666667       0.864407      1.000000        2\n",
      "\n",
      "[137 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#mengambil data train dengan norm_data_iris = true\n",
    "training_data_iris = norm_data_iris[norm_data_iris.training == True]\n",
    "#menghilangkan kolom 'train' yang menampilkan true dan false\n",
    "training_data_iris = training_data_iris.drop('training',axis=1).sample(frac=1)\n",
    "#menampilkan training_data_iris sebanyak 92% dari dataset\n",
    "print(training_data_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buat dataset untuk test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Species\n",
      "131       1.000000      0.750000       0.915254      0.791667        2\n",
      "35        0.194444      0.500000       0.033898      0.041667        0\n",
      "112       0.694444      0.416667       0.762712      0.833333        2\n",
      "148       0.527778      0.583333       0.745763      0.916667        2\n",
      "49        0.194444      0.541667       0.067797      0.041667        0\n",
      "44        0.222222      0.750000       0.152542      0.125000        0\n",
      "106       0.166667      0.208333       0.593220      0.666667        2\n",
      "136       0.555556      0.583333       0.779661      0.958333        2\n",
      "65        0.666667      0.458333       0.576271      0.541667        1\n",
      "40        0.194444      0.625000       0.050847      0.083333        0\n",
      "107       0.833333      0.375000       0.898305      0.708333        2\n",
      "2         0.111111      0.500000       0.050847      0.041667        0\n",
      "80        0.333333      0.166667       0.474576      0.416667        1\n"
     ]
    }
   ],
   "source": [
    "test_data_iris = norm_data_iris[norm_data_iris.training == False]\n",
    "test_data_iris = test_data_iris.drop('training',axis=1).sample(frac=1)\n",
    "print(test_data_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mendefinisikan training input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.80555556 0.41666667 0.81355932 0.625     ]\n",
      " [0.02777778 0.41666667 0.05084746 0.04166667]\n",
      " [0.77777778 0.41666667 0.83050847 0.83333333]\n",
      " [0.22222222 0.75       0.08474576 0.08333333]\n",
      " [0.55555556 0.125      0.57627119 0.5       ]\n",
      " [0.08333333 0.58333333 0.06779661 0.08333333]\n",
      " [0.13888889 0.41666667 0.06779661 0.08333333]\n",
      " [0.36111111 0.29166667 0.54237288 0.5       ]\n",
      " [0.58333333 0.45833333 0.76271186 0.70833333]\n",
      " [0.08333333 0.5        0.06779661 0.04166667]\n",
      " [0.22222222 0.54166667 0.11864407 0.16666667]\n",
      " [0.38888889 0.41666667 0.54237288 0.45833333]\n",
      " [0.41666667 0.29166667 0.49152542 0.45833333]\n",
      " [0.69444444 0.5        0.83050847 0.91666667]\n",
      " [0.41666667 0.33333333 0.69491525 0.95833333]\n",
      " [0.52777778 0.375      0.55932203 0.5       ]\n",
      " [0.27777778 0.70833333 0.08474576 0.04166667]\n",
      " [0.13888889 0.45833333 0.10169492 0.04166667]\n",
      " [0.94444444 0.25       1.         0.91666667]\n",
      " [0.72222222 0.5        0.79661017 0.91666667]\n",
      " [0.44444444 0.41666667 0.54237288 0.58333333]\n",
      " [0.44444444 0.41666667 0.69491525 0.70833333]\n",
      " [0.38888889 0.25       0.42372881 0.375     ]\n",
      " [0.58333333 0.33333333 0.77966102 0.83333333]\n",
      " [0.33333333 0.91666667 0.06779661 0.04166667]\n",
      " [0.25       0.875      0.08474576 0.        ]\n",
      " [0.55555556 0.54166667 0.84745763 1.        ]\n",
      " [0.36111111 0.20833333 0.49152542 0.41666667]\n",
      " [0.38888889 0.375      0.54237288 0.5       ]\n",
      " [0.19444444 0.58333333 0.08474576 0.04166667]\n",
      " [0.30555556 0.79166667 0.11864407 0.125     ]\n",
      " [0.61111111 0.5        0.69491525 0.79166667]\n",
      " [0.38888889 0.33333333 0.52542373 0.5       ]\n",
      " [0.22222222 0.58333333 0.08474576 0.04166667]\n",
      " [0.33333333 0.625      0.05084746 0.04166667]\n",
      " [0.30555556 0.79166667 0.05084746 0.125     ]\n",
      " [0.47222222 0.41666667 0.6440678  0.70833333]\n",
      " [0.66666667 0.45833333 0.62711864 0.58333333]\n",
      " [0.5        0.375      0.62711864 0.54166667]\n",
      " [0.72222222 0.45833333 0.66101695 0.58333333]\n",
      " [0.75       0.5        0.62711864 0.54166667]\n",
      " [0.19444444 0.41666667 0.10169492 0.04166667]\n",
      " [0.61111111 0.41666667 0.71186441 0.79166667]\n",
      " [0.5        0.33333333 0.50847458 0.5       ]\n",
      " [0.22222222 0.20833333 0.33898305 0.41666667]\n",
      " [0.94444444 0.33333333 0.96610169 0.79166667]\n",
      " [0.33333333 0.125      0.50847458 0.5       ]\n",
      " [0.08333333 0.66666667 0.         0.04166667]\n",
      " [0.33333333 0.25       0.57627119 0.45833333]\n",
      " [0.30555556 0.70833333 0.08474576 0.04166667]\n",
      " [0.72222222 0.45833333 0.74576271 0.83333333]\n",
      " [0.13888889 0.58333333 0.15254237 0.04166667]\n",
      " [0.47222222 0.08333333 0.50847458 0.375     ]\n",
      " [0.02777778 0.375      0.06779661 0.04166667]\n",
      " [0.13888889 0.58333333 0.10169492 0.04166667]\n",
      " [0.02777778 0.5        0.05084746 0.04166667]\n",
      " [0.55555556 0.33333333 0.69491525 0.58333333]\n",
      " [0.66666667 0.20833333 0.81355932 0.70833333]\n",
      " [0.19444444 0.66666667 0.06779661 0.04166667]\n",
      " [0.16666667 0.45833333 0.08474576 0.        ]\n",
      " [0.19444444 0.625      0.10169492 0.20833333]\n",
      " [0.5        0.41666667 0.61016949 0.54166667]\n",
      " [0.25       0.625      0.08474576 0.04166667]\n",
      " [0.47222222 0.58333333 0.59322034 0.625     ]\n",
      " [0.52777778 0.08333333 0.59322034 0.58333333]\n",
      " [0.22222222 0.625      0.06779661 0.08333333]\n",
      " [0.58333333 0.29166667 0.72881356 0.75      ]\n",
      " [0.33333333 0.16666667 0.45762712 0.375     ]\n",
      " [0.94444444 0.41666667 0.86440678 0.91666667]\n",
      " [0.41666667 0.25       0.50847458 0.45833333]\n",
      " [0.11111111 0.5        0.10169492 0.04166667]\n",
      " [0.86111111 0.33333333 0.86440678 0.75      ]\n",
      " [0.55555556 0.20833333 0.66101695 0.58333333]\n",
      " [0.58333333 0.5        0.59322034 0.58333333]\n",
      " [0.80555556 0.5        0.84745763 0.70833333]\n",
      " [0.5        0.41666667 0.66101695 0.70833333]\n",
      " [0.66666667 0.41666667 0.71186441 0.91666667]\n",
      " [0.38888889 0.20833333 0.6779661  0.79166667]\n",
      " [0.33333333 0.20833333 0.50847458 0.5       ]\n",
      " [0.66666667 0.54166667 0.79661017 1.        ]\n",
      " [0.08333333 0.45833333 0.08474576 0.04166667]\n",
      " [0.61111111 0.41666667 0.81355932 0.875     ]\n",
      " [0.05555556 0.125      0.05084746 0.08333333]\n",
      " [0.55555556 0.29166667 0.66101695 0.70833333]\n",
      " [0.5        0.25       0.77966102 0.54166667]\n",
      " [0.13888889 0.41666667 0.06779661 0.        ]\n",
      " [0.30555556 0.41666667 0.59322034 0.58333333]\n",
      " [0.25       0.29166667 0.49152542 0.54166667]\n",
      " [0.36111111 0.41666667 0.52542373 0.5       ]\n",
      " [0.58333333 0.375      0.55932203 0.5       ]\n",
      " [0.55555556 0.54166667 0.62711864 0.625     ]\n",
      " [0.61111111 0.33333333 0.61016949 0.58333333]\n",
      " [0.47222222 0.375      0.59322034 0.58333333]\n",
      " [0.41666667 0.29166667 0.69491525 0.75      ]\n",
      " [0.36111111 0.33333333 0.66101695 0.79166667]\n",
      " [0.22222222 0.70833333 0.08474576 0.125     ]\n",
      " [0.22222222 0.75       0.10169492 0.04166667]\n",
      " [0.38888889 0.33333333 0.59322034 0.5       ]\n",
      " [0.16666667 0.45833333 0.08474576 0.        ]\n",
      " [0.38888889 0.75       0.11864407 0.08333333]\n",
      " [0.55555556 0.375      0.77966102 0.70833333]\n",
      " [0.25       0.58333333 0.06779661 0.04166667]\n",
      " [0.16666667 0.16666667 0.38983051 0.375     ]\n",
      " [0.66666667 0.45833333 0.77966102 0.95833333]\n",
      " [0.         0.41666667 0.01694915 0.        ]\n",
      " [0.63888889 0.41666667 0.57627119 0.54166667]\n",
      " [0.66666667 0.54166667 0.79661017 0.83333333]\n",
      " [0.47222222 0.29166667 0.69491525 0.625     ]\n",
      " [0.16666667 0.45833333 0.08474576 0.        ]\n",
      " [0.19444444 0.58333333 0.10169492 0.125     ]\n",
      " [0.69444444 0.33333333 0.6440678  0.54166667]\n",
      " [0.94444444 0.75       0.96610169 0.875     ]\n",
      " [0.58333333 0.5        0.72881356 0.91666667]\n",
      " [0.52777778 0.33333333 0.6440678  0.70833333]\n",
      " [0.55555556 0.20833333 0.6779661  0.75      ]\n",
      " [0.41666667 0.29166667 0.52542373 0.375     ]\n",
      " [0.38888889 1.         0.08474576 0.125     ]\n",
      " [0.5        0.33333333 0.62711864 0.45833333]\n",
      " [0.22222222 0.625      0.06779661 0.04166667]\n",
      " [0.63888889 0.375      0.61016949 0.5       ]\n",
      " [0.91666667 0.41666667 0.94915254 0.83333333]\n",
      " [0.19444444 0.125      0.38983051 0.375     ]\n",
      " [0.41666667 0.29166667 0.69491525 0.75      ]\n",
      " [0.44444444 0.5        0.6440678  0.70833333]\n",
      " [0.61111111 0.41666667 0.76271186 0.70833333]\n",
      " [0.72222222 0.45833333 0.69491525 0.91666667]\n",
      " [0.36111111 0.41666667 0.59322034 0.58333333]\n",
      " [0.58333333 0.33333333 0.77966102 0.875     ]\n",
      " [0.19444444 0.         0.42372881 0.375     ]\n",
      " [0.16666667 0.41666667 0.06779661 0.04166667]\n",
      " [0.41666667 0.83333333 0.03389831 0.04166667]\n",
      " [0.30555556 0.58333333 0.08474576 0.125     ]\n",
      " [0.36111111 0.375      0.44067797 0.5       ]\n",
      " [0.30555556 0.58333333 0.11864407 0.04166667]\n",
      " [0.66666667 0.41666667 0.6779661  0.66666667]\n",
      " [0.47222222 0.08333333 0.6779661  0.58333333]\n",
      " [0.80555556 0.66666667 0.86440678 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "training_inputs = training_data_iris.values[:,:4]\n",
    "print(training_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mendefinikan target outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [1,0,0] = Iris-setosa\n",
    "##### [0,1,0] = Iris-versicolor\n",
    "##### [0,0,1] = Iris-virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_outputs = [[1,0,0],[0,1,0],[0,0,1]]\n",
    "target_outputs = np.array([target_outputs[int(x)] for x in training_data_iris.values[:,4:5]])\n",
    "target_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mendefinisikan jumlah input, hidden layer dan weighting (synaptic) antara input dan hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.16595599  0.44064899 -0.99977125 -0.39533485 -0.70648822]\n",
      " [-0.81532281 -0.62747958 -0.30887855 -0.20646505  0.07763347]\n",
      " [-0.16161097  0.370439   -0.5910955   0.75623487 -0.94522481]\n",
      " [ 0.34093502 -0.1653904   0.11737966 -0.71922612 -0.60379702]]\n"
     ]
    }
   ],
   "source": [
    "jumlah_input = len(training_inputs[0])\n",
    "jumlah_neuron_hidden_layer = 5\n",
    "np.random.seed(1)\n",
    "synaptic_weights_1 = 2 * np.random.random((jumlah_input,jumlah_neuron_hidden_layer))-1\n",
    "print(synaptic_weights_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mendefinisikan jumlah output, generate weighting (synaptic) antara hidden-layer dan output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.60148914  0.93652315 -0.37315164]\n",
      " [ 0.38464523  0.7527783   0.78921333]\n",
      " [-0.82991158 -0.92189043 -0.66033916]\n",
      " [ 0.75628501 -0.80330633 -0.15778475]\n",
      " [ 0.91577906  0.06633057  0.38375423]]\n"
     ]
    }
   ],
   "source": [
    "jumlah_output = len(target_outputs[0])\n",
    "#perhitungan weight_2= menghasilkan jumlah weights dengan cara random dari jumlah input *2 -1\n",
    "synaptic_weights_2 = 2 * np.random.random((jumlah_neuron_hidden_layer, jumlah_output))-1\n",
    "print(synaptic_weights_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mendefinisikan fungsi sigmoid sebagai fungsi aktivasinya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dengan menggunakan rumus sigmoid normalization function 1/1+e^-x\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define fungsi turunan sigmoid\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Propagation\n",
    "sigmoid \n",
    "sigmoid sum (xi.wi) = x1.w1 + x2.w2 + x3.w3 + ...+ xn.wn\n",
    "\n",
    "sigmoid normalizing function\n",
    "sigmoid (x) = 1/1+eksponen^(-x) --> sigmoid(x) = 1/+ eksponen ^(-sum xi.wi)\n",
    "\n",
    "error\n",
    "error = output - actual output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back Propagation\n",
    "sigmoid_derivative\n",
    "sigmoid_derivative(x) = x.(1-x)\n",
    "\n",
    "adjust weights\n",
    "adjust weights= error . input . sigmoid_derivative(output)\n",
    "\n",
    "synaptic weights\n",
    "synaptic weights= [input layer]T dot product [adjust weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synaptic weight antara input dan hidden layer setelah training: \n",
      "[[ 4.51168959  3.25713936 -0.47860512 -3.32093464 -3.07371343]\n",
      " [-3.6557881  -9.57009209 -0.3216099   5.5939924  11.61186448]\n",
      " [-4.43248886  7.99927416  1.40446371  0.88341537 -8.87417102]\n",
      " [ 0.20997199  5.37866541  1.30768602 -3.50053402 -5.62046291]]\n",
      "synaptic weight antara hidden layer dan output setelah training: \n",
      "[[  1.53003295  18.35777117 -26.27544086]\n",
      " [ -5.02395924  13.53113393  -2.13709471]\n",
      " [ -2.23856514 -25.37165161  14.52745429]\n",
      " [  3.6711792   18.29453029 -24.72694514]\n",
      " [  6.6555301  -20.71582243  -7.70569313]]\n",
      "output setelah training: \n",
      "[[2.46042625e-03 3.34906005e-01 6.87674155e-01]\n",
      " [9.99847681e-01 2.24079264e-06 1.98083249e-12]\n",
      " [1.72590266e-03 3.48896041e-02 9.71655578e-01]\n",
      " [9.99905956e-01 2.39331970e-06 1.08838760e-12]\n",
      " [3.01770284e-03 9.57931826e-01 2.38184618e-02]\n",
      " [9.99886375e-01 1.15167963e-06 2.31030955e-12]\n",
      " [9.99769342e-01 5.56414499e-06 1.53793412e-12]\n",
      " [4.80766746e-03 9.15203100e-01 7.36590132e-02]\n",
      " [2.83366280e-03 1.84802757e-01 8.35069680e-01]\n",
      " [9.99875724e-01 2.19401021e-06 1.45964309e-12]\n",
      " [9.99776096e-01 1.46954074e-06 4.24029374e-12]\n",
      " [1.08324627e-02 9.92445570e-01 1.82784017e-03]\n",
      " [5.53436733e-03 9.81584775e-01 1.24496762e-02]\n",
      " [1.71958702e-03 1.22116362e-02 9.91871558e-01]\n",
      " [1.53417652e-03 6.19942754e-03 9.96388377e-01]\n",
      " [5.18388780e-03 9.68965694e-01 2.16700868e-02]\n",
      " [9.99910617e-01 7.06433305e-06 3.47310669e-13]\n",
      " [9.99827222e-01 3.57780036e-06 1.59275121e-12]\n",
      " [1.49323908e-03 3.36547336e-02 9.37763908e-01]\n",
      " [1.74335692e-03 1.93640702e-02 9.86224051e-01]\n",
      " [5.45413699e-03 9.22528943e-01 4.83669297e-02]\n",
      " [3.14941831e-03 2.46221094e-01 7.62243971e-01]\n",
      " [7.62197378e-03 9.97663627e-01 9.80592117e-04]\n",
      " [1.65114644e-03 1.60357444e-02 9.89634853e-01]\n",
      " [9.99922212e-01 9.26211797e-06 3.94142913e-13]\n",
      " [9.99919103e-01 5.36150134e-06 7.69199542e-13]\n",
      " [1.82966070e-03 6.96673060e-03 9.94787225e-01]\n",
      " [4.91267516e-03 9.76694252e-01 1.98703175e-02]\n",
      " [6.87133971e-03 9.71025920e-01 1.48367580e-02]\n",
      " [9.99891615e-01 4.18962255e-06 6.33301138e-13]\n",
      " [9.99901050e-01 1.89378035e-06 1.21782039e-12]\n",
      " [2.61632575e-03 1.68171503e-01 8.51929200e-01]\n",
      " [5.66778836e-03 9.57826397e-01 2.86289526e-02]\n",
      " [9.99891606e-01 5.81470697e-06 4.41587923e-13]\n",
      " [9.99910104e-01 4.12183363e-05 4.12742294e-14]\n",
      " [9.99911902e-01 5.93614526e-06 3.67638276e-13]\n",
      " [3.09941430e-03 3.21477293e-01 6.98505862e-01]\n",
      " [4.13348072e-03 9.10271456e-01 7.08352187e-02]\n",
      " [4.30049637e-03 8.48228056e-01 1.38645726e-01]\n",
      " [3.75443578e-03 8.88910553e-01 9.22498008e-02]\n",
      " [5.01215337e-03 9.78336075e-01 1.27423679e-02]\n",
      " [9.99744225e-01 1.38444933e-05 9.28716478e-13]\n",
      " [2.11525917e-03 8.23324286e-02 9.37394652e-01]\n",
      " [4.97004592e-03 9.77820250e-01 1.49056101e-02]\n",
      " [8.66799878e-03 9.94353274e-01 1.73875700e-03]\n",
      " [1.62799043e-03 5.01084846e-02 9.37952997e-01]\n",
      " [3.09795537e-03 8.20756796e-01 1.97187646e-01]\n",
      " [9.99912570e-01 4.33377386e-06 6.85313741e-13]\n",
      " [4.69543058e-03 8.98707161e-01 9.70423324e-02]\n",
      " [9.99911755e-01 9.79307423e-06 2.36202046e-13]\n",
      " [1.97412645e-03 7.49955498e-02 9.37764126e-01]\n",
      " [9.99872055e-01 9.42286228e-07 3.57422483e-12]\n",
      " [3.89479919e-03 9.93535533e-01 3.81440648e-03]\n",
      " [9.99793390e-01 2.69337752e-06 3.13995270e-12]\n",
      " [9.99887224e-01 1.80456989e-06 1.60914722e-12]\n",
      " [9.99882545e-01 1.59223388e-06 1.90109666e-12]\n",
      " [2.91290237e-03 4.49703027e-01 6.01317090e-01]\n",
      " [1.74076931e-03 6.83342551e-02 9.35748471e-01]\n",
      " [9.99906944e-01 4.29823378e-06 6.06672914e-13]\n",
      " [9.99859963e-01 9.07297596e-06 4.56963442e-13]\n",
      " [9.99843800e-01 5.19753063e-07 5.32698723e-12]\n",
      " [5.24163050e-03 9.23600663e-01 5.46620623e-02]\n",
      " [9.99900147e-01 6.85609193e-06 3.48994462e-13]\n",
      " [1.10975953e-02 9.75556299e-01 3.58717076e-03]\n",
      " [2.53392175e-03 8.57695935e-01 7.97606097e-02]\n",
      " [9.99894997e-01 4.27587885e-06 5.36411705e-13]\n",
      " [1.87189898e-03 6.43161220e-02 9.51135352e-01]\n",
      " [5.28267178e-03 9.89784824e-01 8.02683934e-03]\n",
      " [1.70384657e-03 8.78840424e-02 8.65950695e-01]\n",
      " [4.58256915e-03 9.67144585e-01 2.77592288e-02]\n",
      " [9.99860205e-01 1.89845423e-06 2.04078030e-12]\n",
      " [1.83198444e-03 1.26057733e-01 8.49168124e-01]\n",
      " [2.41972147e-03 4.96228602e-01 5.15393427e-01]\n",
      " [5.85996219e-03 9.52184165e-01 2.55962417e-02]\n",
      " [2.36362991e-03 1.38375068e-01 8.85038153e-01]\n",
      " [2.94631805e-03 2.81446619e-01 7.45945524e-01]\n",
      " [1.73383896e-03 3.80315731e-02 9.68032808e-01]\n",
      " [1.68937163e-03 2.05338718e-02 9.87519144e-01]\n",
      " [3.81426303e-03 8.71789427e-01 1.35972646e-01]\n",
      " [1.67216375e-03 8.66936608e-03 9.94211707e-01]\n",
      " [9.99848124e-01 2.18648235e-06 2.04102070e-12]\n",
      " [1.68498775e-03 1.12355817e-02 9.92946451e-01]\n",
      " [9.57597836e-01 1.51978664e-01 2.03908189e-10]\n",
      " [2.16212660e-03 1.95211677e-01 8.32498771e-01]\n",
      " [2.52938552e-03 1.75533434e-01 8.75117884e-01]\n",
      " [9.99844938e-01 1.11278420e-05 4.42757042e-13]\n",
      " [7.13001746e-03 9.34922556e-01 2.68192070e-02]\n",
      " [5.41685578e-03 9.03647214e-01 6.89126042e-02]\n",
      " [9.93615311e-03 9.86310268e-01 3.49602333e-03]\n",
      " [4.85667504e-03 9.76829647e-01 1.58315397e-02]\n",
      " [6.26834810e-03 9.27462201e-01 3.41804360e-02]\n",
      " [3.14934364e-03 8.30247452e-01 1.54915291e-01]\n",
      " [4.05910284e-03 7.99891824e-01 1.86487595e-01]\n",
      " [2.02529647e-03 4.13069362e-02 9.73741942e-01]\n",
      " [2.20444960e-03 4.68459904e-02 9.67710318e-01]\n",
      " [9.99895948e-01 1.69766533e-06 1.34701426e-12]\n",
      " [9.99908508e-01 2.75384340e-06 1.04893502e-12]\n",
      " [5.21633758e-03 9.15774315e-01 6.64179400e-02]\n",
      " [9.99859963e-01 9.07297596e-06 4.56963442e-13]\n",
      " [9.99906150e-01 8.11980716e-06 2.54195453e-13]\n",
      " [2.26373977e-03 6.94147876e-02 9.50595825e-01]\n",
      " [9.99896481e-01 1.11491419e-05 2.04319995e-13]\n",
      " [7.82153408e-03 9.91671568e-01 4.19598202e-03]\n",
      " [1.59330893e-03 1.09317514e-02 9.92578363e-01]\n",
      " [9.99881483e-01 3.92009091e-06 8.43310000e-13]\n",
      " [4.53872871e-03 9.67827233e-01 2.17752041e-02]\n",
      " [2.34789970e-03 6.11470653e-02 9.49619338e-01]\n",
      " [2.53682677e-03 1.98277555e-01 8.51139798e-01]\n",
      " [9.99859963e-01 9.07297596e-06 4.56963442e-13]\n",
      " [9.99859318e-01 1.40498119e-06 2.13138899e-12]\n",
      " [3.25883058e-03 9.15105599e-01 6.61558168e-02]\n",
      " [2.59281056e-03 7.00177655e-02 9.27164332e-01]\n",
      " [1.98071423e-03 2.62709209e-02 9.81121791e-01]\n",
      " [2.35934852e-03 2.15595569e-01 8.22992016e-01]\n",
      " [1.88053526e-03 1.34629837e-01 8.64450863e-01]\n",
      " [7.14924731e-03 9.93385238e-01 3.81927927e-03]\n",
      " [9.99917535e-01 4.69781385e-06 6.80031281e-13]\n",
      " [4.79888334e-03 9.36943643e-01 5.54736614e-02]\n",
      " [9.99903298e-01 6.62925650e-06 3.60556576e-13]\n",
      " [4.26415029e-03 9.61781142e-01 2.96209170e-02]\n",
      " [1.58082927e-03 2.26943352e-02 9.79608761e-01]\n",
      " [5.99624208e-03 9.89384215e-01 7.67421875e-03]\n",
      " [2.02529647e-03 4.13069362e-02 9.73741942e-01]\n",
      " [4.65818495e-03 6.63272337e-01 2.40907905e-01]\n",
      " [2.41724001e-03 1.22307519e-01 9.05170793e-01]\n",
      " [1.86089084e-03 7.79105733e-02 9.24289469e-01]\n",
      " [6.17161353e-03 9.10213598e-01 4.81410666e-02]\n",
      " [1.56299669e-03 1.13085074e-02 9.92667236e-01]\n",
      " [3.77848592e-03 9.64206208e-01 3.80554598e-02]\n",
      " [9.99805521e-01 1.17487326e-05 5.61068089e-13]\n",
      " [9.99930390e-01 6.67664366e-05 3.21038537e-14]\n",
      " [9.99858272e-01 7.13506325e-06 3.68656114e-13]\n",
      " [9.33821034e-03 9.87236344e-01 3.12362903e-03]\n",
      " [9.99878079e-01 9.77424528e-06 2.89388738e-13]\n",
      " [2.77512434e-03 4.95803607e-01 5.17946050e-01]\n",
      " [2.06867161e-03 2.68253433e-01 7.46606534e-01]\n",
      " [1.88162804e-03 1.40588705e-02 9.89238099e-01]]\n",
      "Error: \n",
      "[[-2.46042625e-03 -3.34906005e-01  3.12325845e-01]\n",
      " [ 1.52319454e-04 -2.24079264e-06 -1.98083249e-12]\n",
      " [-1.72590266e-03 -3.48896041e-02  2.83444215e-02]\n",
      " [ 9.40440651e-05 -2.39331970e-06 -1.08838760e-12]\n",
      " [-3.01770284e-03  4.20681742e-02 -2.38184618e-02]\n",
      " [ 1.13625395e-04 -1.15167963e-06 -2.31030955e-12]\n",
      " [ 2.30657735e-04 -5.56414499e-06 -1.53793412e-12]\n",
      " [-4.80766746e-03  8.47968998e-02 -7.36590132e-02]\n",
      " [-2.83366280e-03 -1.84802757e-01  1.64930320e-01]\n",
      " [ 1.24275903e-04 -2.19401021e-06 -1.45964309e-12]\n",
      " [ 2.23904031e-04 -1.46954074e-06 -4.24029374e-12]\n",
      " [-1.08324627e-02  7.55442989e-03 -1.82784017e-03]\n",
      " [-5.53436733e-03  1.84152252e-02 -1.24496762e-02]\n",
      " [-1.71958702e-03 -1.22116362e-02  8.12844153e-03]\n",
      " [-1.53417652e-03 -6.19942754e-03  3.61162322e-03]\n",
      " [-5.18388780e-03  3.10343057e-02 -2.16700868e-02]\n",
      " [ 8.93825025e-05 -7.06433305e-06 -3.47310669e-13]\n",
      " [ 1.72777950e-04 -3.57780036e-06 -1.59275121e-12]\n",
      " [-1.49323908e-03 -3.36547336e-02  6.22360924e-02]\n",
      " [-1.74335692e-03 -1.93640702e-02  1.37759491e-02]\n",
      " [-5.45413699e-03  7.74710573e-02 -4.83669297e-02]\n",
      " [-3.14941831e-03 -2.46221094e-01  2.37756029e-01]\n",
      " [-7.62197378e-03  2.33637276e-03 -9.80592117e-04]\n",
      " [-1.65114644e-03 -1.60357444e-02  1.03651466e-02]\n",
      " [ 7.77879318e-05 -9.26211797e-06 -3.94142913e-13]\n",
      " [ 8.08972786e-05 -5.36150134e-06 -7.69199542e-13]\n",
      " [-1.82966070e-03 -6.96673060e-03  5.21277495e-03]\n",
      " [-4.91267516e-03  2.33057479e-02 -1.98703175e-02]\n",
      " [-6.87133971e-03  2.89740799e-02 -1.48367580e-02]\n",
      " [ 1.08384906e-04 -4.18962255e-06 -6.33301138e-13]\n",
      " [ 9.89498340e-05 -1.89378035e-06 -1.21782039e-12]\n",
      " [-2.61632575e-03 -1.68171503e-01  1.48070800e-01]\n",
      " [-5.66778836e-03  4.21736034e-02 -2.86289526e-02]\n",
      " [ 1.08393755e-04 -5.81470697e-06 -4.41587923e-13]\n",
      " [ 8.98955611e-05 -4.12183363e-05 -4.12742294e-14]\n",
      " [ 8.80976623e-05 -5.93614526e-06 -3.67638276e-13]\n",
      " [-3.09941430e-03 -3.21477293e-01  3.01494138e-01]\n",
      " [-4.13348072e-03  8.97285442e-02 -7.08352187e-02]\n",
      " [-4.30049637e-03  1.51771944e-01 -1.38645726e-01]\n",
      " [-3.75443578e-03  1.11089447e-01 -9.22498008e-02]\n",
      " [-5.01215337e-03  2.16639250e-02 -1.27423679e-02]\n",
      " [ 2.55774530e-04 -1.38444933e-05 -9.28716478e-13]\n",
      " [-2.11525917e-03 -8.23324286e-02  6.26053484e-02]\n",
      " [-4.97004592e-03  2.21797502e-02 -1.49056101e-02]\n",
      " [-8.66799878e-03  5.64672562e-03 -1.73875700e-03]\n",
      " [-1.62799043e-03 -5.01084846e-02  6.20470030e-02]\n",
      " [-3.09795537e-03  1.79243204e-01 -1.97187646e-01]\n",
      " [ 8.74298514e-05 -4.33377386e-06 -6.85313741e-13]\n",
      " [-4.69543058e-03  1.01292839e-01 -9.70423324e-02]\n",
      " [ 8.82454411e-05 -9.79307423e-06 -2.36202046e-13]\n",
      " [-1.97412645e-03 -7.49955498e-02  6.22358743e-02]\n",
      " [ 1.27945476e-04 -9.42286228e-07 -3.57422483e-12]\n",
      " [-3.89479919e-03  6.46446658e-03 -3.81440648e-03]\n",
      " [ 2.06609521e-04 -2.69337752e-06 -3.13995270e-12]\n",
      " [ 1.12775723e-04 -1.80456989e-06 -1.60914722e-12]\n",
      " [ 1.17454991e-04 -1.59223388e-06 -1.90109666e-12]\n",
      " [-2.91290237e-03 -4.49703027e-01  3.98682910e-01]\n",
      " [-1.74076931e-03 -6.83342551e-02  6.42515291e-02]\n",
      " [ 9.30559384e-05 -4.29823378e-06 -6.06672914e-13]\n",
      " [ 1.40036728e-04 -9.07297596e-06 -4.56963442e-13]\n",
      " [ 1.56199672e-04 -5.19753063e-07 -5.32698723e-12]\n",
      " [-5.24163050e-03  7.63993370e-02 -5.46620623e-02]\n",
      " [ 9.98534919e-05 -6.85609193e-06 -3.48994462e-13]\n",
      " [-1.10975953e-02  2.44437014e-02 -3.58717076e-03]\n",
      " [-2.53392175e-03  1.42304065e-01 -7.97606097e-02]\n",
      " [ 1.05003140e-04 -4.27587885e-06 -5.36411705e-13]\n",
      " [-1.87189898e-03 -6.43161220e-02  4.88646482e-02]\n",
      " [-5.28267178e-03  1.02151758e-02 -8.02683934e-03]\n",
      " [-1.70384657e-03 -8.78840424e-02  1.34049305e-01]\n",
      " [-4.58256915e-03  3.28554155e-02 -2.77592288e-02]\n",
      " [ 1.39795466e-04 -1.89845423e-06 -2.04078030e-12]\n",
      " [-1.83198444e-03 -1.26057733e-01  1.50831876e-01]\n",
      " [-2.41972147e-03  5.03771398e-01 -5.15393427e-01]\n",
      " [-5.85996219e-03  4.78158353e-02 -2.55962417e-02]\n",
      " [-2.36362991e-03 -1.38375068e-01  1.14961847e-01]\n",
      " [-2.94631805e-03 -2.81446619e-01  2.54054476e-01]\n",
      " [-1.73383896e-03 -3.80315731e-02  3.19671918e-02]\n",
      " [-1.68937163e-03 -2.05338718e-02  1.24808556e-02]\n",
      " [-3.81426303e-03  1.28210573e-01 -1.35972646e-01]\n",
      " [-1.67216375e-03 -8.66936608e-03  5.78829330e-03]\n",
      " [ 1.51875897e-04 -2.18648235e-06 -2.04102070e-12]\n",
      " [-1.68498775e-03 -1.12355817e-02  7.05354916e-03]\n",
      " [ 4.24021642e-02 -1.51978664e-01 -2.03908189e-10]\n",
      " [-2.16212660e-03 -1.95211677e-01  1.67501229e-01]\n",
      " [-2.52938552e-03 -1.75533434e-01  1.24882116e-01]\n",
      " [ 1.55062426e-04 -1.11278420e-05 -4.42757042e-13]\n",
      " [-7.13001746e-03  6.50774441e-02 -2.68192070e-02]\n",
      " [-5.41685578e-03  9.63527858e-02 -6.89126042e-02]\n",
      " [-9.93615311e-03  1.36897316e-02 -3.49602333e-03]\n",
      " [-4.85667504e-03  2.31703533e-02 -1.58315397e-02]\n",
      " [-6.26834810e-03  7.25377992e-02 -3.41804360e-02]\n",
      " [-3.14934364e-03  1.69752548e-01 -1.54915291e-01]\n",
      " [-4.05910284e-03  2.00108176e-01 -1.86487595e-01]\n",
      " [-2.02529647e-03 -4.13069362e-02  2.62580584e-02]\n",
      " [-2.20444960e-03 -4.68459904e-02  3.22896822e-02]\n",
      " [ 1.04051903e-04 -1.69766533e-06 -1.34701426e-12]\n",
      " [ 9.14918507e-05 -2.75384340e-06 -1.04893502e-12]\n",
      " [-5.21633758e-03  8.42256854e-02 -6.64179400e-02]\n",
      " [ 1.40036728e-04 -9.07297596e-06 -4.56963442e-13]\n",
      " [ 9.38498898e-05 -8.11980716e-06 -2.54195453e-13]\n",
      " [-2.26373977e-03 -6.94147876e-02  4.94041753e-02]\n",
      " [ 1.03518895e-04 -1.11491419e-05 -2.04319995e-13]\n",
      " [-7.82153408e-03  8.32843208e-03 -4.19598202e-03]\n",
      " [-1.59330893e-03 -1.09317514e-02  7.42163723e-03]\n",
      " [ 1.18517089e-04 -3.92009091e-06 -8.43310000e-13]\n",
      " [-4.53872871e-03  3.21727674e-02 -2.17752041e-02]\n",
      " [-2.34789970e-03 -6.11470653e-02  5.03806620e-02]\n",
      " [-2.53682677e-03  8.01722445e-01 -8.51139798e-01]\n",
      " [ 1.40036728e-04 -9.07297596e-06 -4.56963442e-13]\n",
      " [ 1.40681995e-04 -1.40498119e-06 -2.13138899e-12]\n",
      " [-3.25883058e-03  8.48944011e-02 -6.61558168e-02]\n",
      " [-2.59281056e-03 -7.00177655e-02  7.28356684e-02]\n",
      " [-1.98071423e-03 -2.62709209e-02  1.88782086e-02]\n",
      " [-2.35934852e-03 -2.15595569e-01  1.77007984e-01]\n",
      " [-1.88053526e-03 -1.34629837e-01  1.35549137e-01]\n",
      " [-7.14924731e-03  6.61476228e-03 -3.81927927e-03]\n",
      " [ 8.24649855e-05 -4.69781385e-06 -6.80031281e-13]\n",
      " [-4.79888334e-03  6.30563571e-02 -5.54736614e-02]\n",
      " [ 9.67022639e-05 -6.62925650e-06 -3.60556576e-13]\n",
      " [-4.26415029e-03  3.82188576e-02 -2.96209170e-02]\n",
      " [-1.58082927e-03 -2.26943352e-02  2.03912392e-02]\n",
      " [-5.99624208e-03  1.06157850e-02 -7.67421875e-03]\n",
      " [-2.02529647e-03 -4.13069362e-02  2.62580584e-02]\n",
      " [-4.65818495e-03  3.36727663e-01 -2.40907905e-01]\n",
      " [-2.41724001e-03 -1.22307519e-01  9.48292066e-02]\n",
      " [-1.86089084e-03 -7.79105733e-02  7.57105312e-02]\n",
      " [-6.17161353e-03  8.97864020e-02 -4.81410666e-02]\n",
      " [-1.56299669e-03 -1.13085074e-02  7.33276448e-03]\n",
      " [-3.77848592e-03  3.57937921e-02 -3.80554598e-02]\n",
      " [ 1.94479420e-04 -1.17487326e-05 -5.61068089e-13]\n",
      " [ 6.96095727e-05 -6.67664366e-05 -3.21038537e-14]\n",
      " [ 1.41727546e-04 -7.13506325e-06 -3.68656114e-13]\n",
      " [-9.33821034e-03  1.27636562e-02 -3.12362903e-03]\n",
      " [ 1.21920897e-04 -9.77424528e-06 -2.89388738e-13]\n",
      " [-2.77512434e-03  5.04196393e-01 -5.17946050e-01]\n",
      " [-2.06867161e-03 -2.68253433e-01  2.53393466e-01]\n",
      " [-1.88162804e-03 -1.40588705e-02  1.07619006e-02]]\n",
      "Error Mean: \n",
      "0.04387035671091587\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "for i in range(50):\n",
    "    # Analisa forward propagation untuk perhitungan output dan kalkulasi error\n",
    "    outputs_1 = sigmoid(np.dot(training_inputs,synaptic_weights_1)) # aktivasi nilai pada hidden layer\n",
    "    outputs_2 = sigmoid(np.dot(outputs_1,synaptic_weights_2)) # aktivasi nilai pada output layer\n",
    "    error = (target_outputs - outputs_2) #selisih nilai outputs dengan actual outputs\n",
    "    error_mean = abs(error).mean()\n",
    "    \n",
    "    # Analisa back propagation untuk mendapatkan adjustment dan update weighting\n",
    "    adjustment_2 = error * sigmoid_derivative(outputs_2) #adjustment output layer\n",
    "    adjustment_1 = adjustment_2.dot(synaptic_weights_2.T) * sigmoid_derivative(outputs_1) #adjustment hidden layer\n",
    "\n",
    "    synaptic_weights_2 += outputs_1.T.dot(adjustment_2) * learning_rate #update weight output layer\n",
    "    synaptic_weights_1 += training_inputs.T.dot(adjustment_1) * learning_rate #update weight hidden layer\n",
    "print('synaptic weight antara input dan hidden layer setelah training: ')\n",
    "print(synaptic_weights_1)\n",
    "\n",
    "print('synaptic weight antara hidden layer dan output setelah training: ')\n",
    "print(synaptic_weights_2)\n",
    "\n",
    "print('output setelah training: ')\n",
    "print(outputs_2)\n",
    "\n",
    "print(\"Error: \")\n",
    "print(error)\n",
    "\n",
    "print(\"Error Mean: \")\n",
    "print(error_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction menggunakan test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "test_inputs = test_data_iris.values[:,:4]\n",
    "len(test_inputs)\n",
    "target_outputs = [[1,0,0],[0,1,0],[0,0,1]]\n",
    "target_outputs = np.array([target_outputs[int(x)] for x in test_data_iris.values[:,4:5]])\n",
    "print(target_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.003 0.263 0.711]\n",
      " [1.    0.    0.   ]\n",
      " [0.002 0.047 0.964]\n",
      " [0.003 0.074 0.921]\n",
      " [1.    0.    0.   ]\n",
      " [1.    0.    0.   ]\n",
      " [0.003 0.139 0.894]\n",
      " [0.002 0.03  0.973]\n",
      " [0.005 0.979 0.012]\n",
      " [1.    0.    0.   ]\n",
      " [0.002 0.061 0.949]\n",
      " [1.    0.    0.   ]\n",
      " [0.004 0.972 0.025]]\n"
     ]
    }
   ],
   "source": [
    "# output pada hidden layer\n",
    "outputs_1 = sigmoid(np.dot(test_inputs,synaptic_weights_1))\n",
    "# estimasi pada output layer\n",
    "outputs_2 = sigmoid(np.dot(outputs_1,synaptic_weights_2)) \n",
    "print(np.round(outputs_2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hasil Prediksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Species       Prediction\n",
      "131   Iris-virginica   Iris-virginica\n",
      "35       Iris-setosa      Iris-setosa\n",
      "112   Iris-virginica   Iris-virginica\n",
      "148   Iris-virginica   Iris-virginica\n",
      "49       Iris-setosa      Iris-setosa\n",
      "44       Iris-setosa      Iris-setosa\n",
      "106   Iris-virginica   Iris-virginica\n",
      "136   Iris-virginica   Iris-virginica\n",
      "65   Iris-versicolor  Iris-versicolor\n",
      "40       Iris-setosa      Iris-setosa\n",
      "107   Iris-virginica   Iris-virginica\n",
      "2        Iris-setosa      Iris-setosa\n",
      "80   Iris-versicolor  Iris-versicolor\n",
      "\n",
      "Correct:  13  /  13 100.0 %\n"
     ]
    }
   ],
   "source": [
    "#membulatkan hasil pada outputs\n",
    "prediksi = np.around(outputs_2) \n",
    "\n",
    "# Discrepancy hasil estimasi dengan yang seharusnya\n",
    "# bandingkan hasil prediksi dengan label target\n",
    "discrepancy = np.argmax(prediksi, axis=1) == np.argmax(target_outputs, axis=1) \n",
    "\n",
    "\n",
    "# Menghitung persentase hasil yang benar terhadap semua hasil test\n",
    "presentase_benar = np.sum(discrepancy)/len(discrepancy)\n",
    "\n",
    "\n",
    "hasil_test = test_data_iris[['Species']].replace([0,1,2],['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'])\n",
    "hasil_test['Prediction'] = np.argmax(outputs_2, axis=1)\n",
    "hasil_test['Prediction'] = hasil_test['Prediction'].replace([0,1,2],['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'])\n",
    "\n",
    "print(hasil_test)\n",
    "print('')\n",
    "print('Correct: ', sum(discrepancy), ' / ', len(hasil_test), (presentase_benar*100), '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
